{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f894eaf2-f871-4c9e-a9f0-cf2f3113e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting tkan\n",
      "  Downloading tkan-0.4.3-py3-none-any.whl (7.4 kB)\n",
      "Collecting temporal_linear_network\n",
      "  Downloading temporal_linear_network-0.1.2-py3-none-any.whl (7.0 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting jax[cuda12]\n",
      "  Downloading jax-0.4.38-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 KB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting keras_sig\n",
      "  Downloading keras_sig-1.0.1-py3-none-any.whl (11 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 KB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 KB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting keras_efficient_kan<0.2.0,>=0.1.9\n",
      "  Downloading keras_efficient_kan-0.1.10-py3-none-any.whl (3.5 kB)\n",
      "Collecting keras<4.0.0,>=3.0.0\n",
      "  Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting jaxlib<=0.4.38,>=0.4.38\n",
      "  Downloading jaxlib-0.4.38-cp310-cp310-manylinux2014_x86_64.whl (101.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting ml_dtypes>=0.4.0\n",
      "  Downloading ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting opt_einsum\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 KB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting jax-cuda12-plugin[with_cuda]<=0.4.38,>=0.4.38\n",
      "  Downloading jax_cuda12_plugin-0.4.38-cp310-cp310-manylinux2014_x86_64.whl (16.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting jaxtyping<0.3.0,>=0.2.36\n",
      "  Downloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting jax-cuda12-pjrt==0.4.38\n",
      "  Downloading jax_cuda12_pjrt-0.4.38-py3-none-manylinux2014_x86_64.whl (102.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-nccl-cu12>=2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.1\n",
      "  Downloading nvidia_cudnn_cu12-9.6.0.74-py3-none-manylinux_2_27_x86_64.whl (508.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.1/508.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cuda-cupti-cu12>=12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "Collecting nvidia-cuda-runtime-cu12>=12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 KB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.6.85\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.6.85-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (21.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.2/21.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cublas-cu12>=12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-nvjitlink-cu12>=12.1.105\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 KB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting optree\n",
      "  Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.3/381.3 KB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras<4.0.0,>=3.0.0->tkan) (4.12.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (2.18.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, jax-cuda12-pjrt, tzdata, threadpoolctl, pyarrow, pillow, optree, opt_einsum, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mdurl, kiwisolver, joblib, jaxtyping, jax-cuda12-plugin, fonttools, cycler, absl-py, scipy, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, ml_dtypes, markdown-it-py, h5py, contourpy, scikit-learn, rich, nvidia-cusolver-cu12, matplotlib, jaxlib, seaborn, keras, jax, temporal_linear_network, keras_sig, keras_efficient_kan, tkan\n",
      "Successfully installed absl-py-2.1.0 contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 h5py-3.12.1 jax-0.4.38 jax-cuda12-pjrt-0.4.38 jax-cuda12-plugin-0.4.38 jaxlib-0.4.38 jaxtyping-0.2.36 joblib-1.4.2 keras-3.7.0 keras_efficient_kan-0.1.10 keras_sig-1.0.1 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 ml_dtypes-0.5.0 namex-0.0.8 numpy-2.2.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvcc-cu12-12.6.85 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.6.0.74 nvidia-cufft-cu12-11.3.0.4 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.23.4 nvidia-nvjitlink-cu12-12.6.85 opt_einsum-3.4.0 optree-0.13.1 pandas-2.2.3 pillow-11.0.0 pyarrow-18.1.0 pytz-2024.2 rich-13.9.4 scikit-learn-1.6.0 scipy-1.14.1 seaborn-0.13.2 temporal_linear_network-0.1.2 threadpoolctl-3.5.0 tkan-0.4.3 tzdata-2024.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib pyarrow scikit-learn tkan temporal_linear_network scipy \"jax[cuda12]\" seaborn keras_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee96e2-c485-456b-9888-203425c3cfea",
   "metadata": {},
   "source": [
    "## Dynamic VWAP paper all results\n",
    "\n",
    "Runned using an 3 RTX 4090 + AMD EPYC 9654\n",
    "\n",
    "This notebook was used to run all the results displayed in the paper, but as the session disconnected the notebook itself didn't registered, so only the graphs and table where saved and are not present in the notebook. \n",
    "You can obtain same results are the one in the paper rerunning this notebook still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c489534-bd5f-491e-ae7d-ea4bacd1f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on ['BTC', 'BCH', 'EOS', 'TRX', 'LINK', 'ADA', 'DASH', 'XTZ', 'BNB', 'IOTA', 'VET', 'QTUM', 'THETA', 'ZIL', 'ZRX', 'OMG', 'SXP', 'BAND', 'MKR', 'DOT', 'YFI', 'BAL', 'TRB', 'SUSHI', 'SOL', 'STORJ', 'UNI', 'FTM', 'FLM', 'KSM', 'FIL', 'RSR', 'MATIC', 'BEL', 'ALPHA', 'SKL', '1INCH', 'SAND', 'LIT', 'UNFI']\n",
      "\n",
      "testing on ['BTC', 'ETH', 'BCH', 'XRP', 'EOS', 'LTC', 'TRX', 'ETC', 'LINK', 'XLM', 'ADA', 'XMR', 'DASH', 'ZEC', 'XTZ', 'ATOM', 'BNB', 'ONT', 'IOTA', 'BAT', 'VET', 'NEO', 'QTUM', 'IOST', 'THETA', 'ALGO', 'ZIL', 'KNC', 'ZRX', 'COMP', 'OMG', 'DOGE', 'SXP', 'KAVA', 'BAND', 'RLC', 'MKR', 'SNX', 'DOT', 'DEFI', 'YFI', 'CRV', 'BAL', 'WAVES', 'TRB', 'RUNE', 'SUSHI', 'EGLD', 'SOL', 'ICX', 'STORJ', 'BLZ', 'UNI', 'AVAX', 'FTM', 'ENJ', 'FLM', 'REN', 'KSM', 'NEAR', 'FIL', 'AAVE', 'RSR', 'LRC', 'MATIC', 'OCEAN', 'BEL', 'AXS', 'ALPHA', 'ZEN', 'SKL', 'GRT', '1INCH', 'CHZ', 'SAND', 'ANKR', 'LIT', 'CTK', 'UNFI', 'REEF']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0), CudaDevice(id=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import jax\n",
    "BACKEND = 'jax'  # You can use any backend here\n",
    "os.environ['KERAS_BACKEND'] = BACKEND\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras.initializers import Initializer\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import Dense, LSTM, Input, Reshape\n",
    "\n",
    "from tkan import TKAN\n",
    "from tln import TLN\n",
    "\n",
    "from keras_sig import SigLayer\n",
    "\n",
    "import keras \n",
    "from keras import ops\n",
    "from keras import Model, Input\n",
    "from keras.layers import Layer, LSTM, Dense, Input, Add, LayerNormalization, Multiply, Reshape, Activation, TimeDistributed, Flatten, Lambda, MultiHeadAttention, Concatenate, Dropout\n",
    "from keras_efficient_kan import KANLinear\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(1) \n",
    "\n",
    "early_stopping_callback = lambda : keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00001,\n",
    "    patience=13,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")\n",
    "lr_callback = lambda : keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.25,\n",
    "    patience=6,\n",
    "    mode=\"min\",\n",
    "    min_delta=0.00001,\n",
    "    min_lr=0.000025,\n",
    "    verbose=0,\n",
    ")\n",
    "callbacks = lambda : [early_stopping_callback(), lr_callback(), keras.callbacks.TerminateOnNaN()]\n",
    "\n",
    "\n",
    "# Initialize data parallel distribution\n",
    "# It will automatically detect all available GPU devices\n",
    "data_parallel = keras.distribution.DataParallel()\n",
    "\n",
    "# Set the global distribution\n",
    "keras.distribution.set_distribution(data_parallel)\n",
    "\n",
    "import jax\n",
    "N_DEVICES = len(jax.devices())\n",
    "\n",
    "N_MAX_EPOCHS = 1000\n",
    "N_RUNS = 3\n",
    "\n",
    "NOTIONAL_PARQUET_PATH = \"hourly_notionals.parquet\"\n",
    "VOLUME_PARQUET_PATH = \"hourly_volumes.parquet\"\n",
    "CLOSES_PARQUET_PATH = \"hourly_closes.parquet\"\n",
    "\n",
    "sorted_assets = list((pd.read_parquet(VOLUME_PARQUET_PATH)==0).sum(axis=0).sort_values().index)\n",
    "N_ASSETS = 80\n",
    "all_assets = sorted_assets[:N_ASSETS]\n",
    "train_assets = sorted_assets[:N_ASSETS][::2] # 1 over 2\n",
    "print('training on', train_assets)\n",
    "print()\n",
    "print('testing on', all_assets)\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712d90c4-6356-44fb-8818-2d2708b8e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_without_ahead_inputs(vwaps: np.ndarray, volumes: np.ndarray, features: np.ndarray, lookback: int, n_ahead: int, autoscale_target: bool = True):\n",
    "    n_row = vwaps.shape[0]\n",
    "    X = {'prices': np.zeros((n_row - lookback - n_ahead, lookback, 1)), 'volumes': np.zeros((n_row - lookback - n_ahead, lookback, 1)), 'features': np.zeros((n_row - lookback - n_ahead, lookback, features.shape[1]))}\n",
    "    y = {'prices': np.zeros((n_row - lookback - n_ahead, n_ahead, 1)), 'volumes': np.zeros((n_row - lookback - n_ahead, n_ahead, 1))}\n",
    "    offset=0\n",
    "    print('hir?')\n",
    "    for row in range(lookback, n_row - n_ahead):\n",
    "        X[row - lookback-offset] = features[row - lookback:row]\n",
    "        if autoscale_target:\n",
    "            s=np.sum(volumes[row - lookback:row])\n",
    "            if s>0 and np.sum(volumes[row:row + n_ahead])>0:\n",
    "                y['prices'][row - lookback-offset] = np.expand_dims(vwaps[row:row + n_ahead] / vwaps[row - lookback], axis=-1)\n",
    "                y['volumes'][row - lookback-offset] = np.expand_dims(volumes[row:row + n_ahead] / s, axis=-1)\n",
    "            else:\n",
    "                \n",
    "                offset+=1\n",
    "        else:\n",
    "            y['prices'][row - lookback] = np.expand_dims(vwaps[row:row + n_ahead], axis=-1)\n",
    "            y['volumes'][row - lookback] = np.expand_dims(volumes[row:row + n_ahead], axis=-1)\n",
    "    y = np.concatenate([y['volumes'], y['prices']], axis=-1)\n",
    "    \n",
    "    return X[:-offset], y[:-offset]\n",
    "\n",
    "def prepare_data_with_ahead_inputs(vwaps: np.ndarray, volumes: np.ndarray, features: np.ndarray, lookback: int, n_ahead: int, autoscale_target: bool = True):\n",
    "    n_row = vwaps.shape[0]\n",
    "    X = np.zeros((n_row - lookback - n_ahead, lookback + n_ahead - 1, features.shape[1]))\n",
    "    y = {'prices': np.zeros((n_row - lookback - n_ahead, n_ahead, 1)), 'volumes': np.zeros((n_row - lookback - n_ahead, n_ahead, 1))}\n",
    "    offset=0\n",
    "    for row in range(lookback, n_row - n_ahead):\n",
    "        X[row - lookback-offset] = features[row - lookback:row + n_ahead - 1]\n",
    "        if autoscale_target:\n",
    "            s=np.sum(volumes[row - lookback:row])\n",
    "            if s>0 and np.sum(volumes[row:row + n_ahead])>0:\n",
    "                y['prices'][row - lookback-offset] = np.expand_dims(vwaps[row:row + n_ahead] / vwaps[row - lookback], axis=-1)\n",
    "                y['volumes'][row - lookback-offset] = np.expand_dims(volumes[row:row + n_ahead] / s, axis=-1)\n",
    "            else:\n",
    "                offset+=1\n",
    "        else:\n",
    "            y['prices'][row - lookback] = np.expand_dims(vwaps[row:row + n_ahead], axis=-1)\n",
    "            y['volumes'][row - lookback] = np.expand_dims(volumes[row:row + n_ahead], axis=-1)\n",
    "    y = np.concatenate([y['volumes'], y['prices']], axis=-1)\n",
    "    return X[:-offset-1], y[:-offset-1]\n",
    "\n",
    "\n",
    "def full_generate(target_asset, lookback = 120, n_ahead = 12, test_split = 0.2, include_ahead_inputs = False, autoscale_target=True):\n",
    "    volumes = pd.read_parquet(VOLUME_PARQUET_PATH).astype(np.float32)\n",
    "    notionals = pd.read_parquet(NOTIONAL_PARQUET_PATH).astype(np.float32)\n",
    "    assets = [target_asset]\n",
    "    \n",
    "    assert target_asset in assets\n",
    "    volumes = volumes[assets].dropna()\n",
    "    notionals = notionals[assets].dropna()\n",
    "    notionals = notionals.loc[volumes.index]\n",
    "    volumes = volumes.loc[notionals.index]\n",
    "    vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
    "    vwaps = vwaps.ffill().dropna()\n",
    "    notionals = notionals.loc[vwaps.index]\n",
    "    volumes = volumes.loc[vwaps.index]\n",
    "    #Create feature\n",
    "    features = volumes / volumes.shift(lookback + n_ahead).rolling(24 * 7 * 2).mean()\n",
    "    features['hour'] = volumes.index.hour\n",
    "    features['dow'] = volumes.index.dayofweek\n",
    "    for asset in assets:\n",
    "        features[f'returns {asset}'] = vwaps[asset] / vwaps[asset].shift() - 1.\n",
    "    \n",
    "    #Create volume and prices\n",
    "    volumes = volumes[target_asset]\n",
    "    vwaps = vwaps[target_asset]\n",
    "    \n",
    "    #Remove NaN and align\n",
    "    features = features.loc[volumes.index].dropna()\n",
    "    volumes = volumes.loc[features.index]\n",
    "    vwaps = vwaps.ffill().loc[volumes.index]\n",
    "\n",
    "    if include_ahead_inputs:\n",
    "        X, y = prepare_data_with_ahead_inputs(vwaps.values, volumes.values, features.values, lookback, n_ahead, autoscale_target =  autoscale_target)\n",
    "    else:\n",
    "        X, y = prepare_data_without_ahead_inputs(vwaps.values, volumes.values, features.values, lookback, n_ahead, autoscale_target = autoscale_target)\n",
    "    \n",
    "    test_row = int(len(y) * (1 - test_split))\n",
    "    \n",
    "    X_train = X[:test_row]\n",
    "    X_test = X[test_row:]\n",
    "    \n",
    "    y_train, y_test = y[:test_row], y[test_row:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09cd793-14e7-45b7-afa3-928d8a77350d",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974de24e-30b5-4a1d-a6db-21e5c270b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_vwap_loss(y_true, y_pred):\n",
    "    # Ensure all operations are done with float32\n",
    "    vwap_achieved = keras.ops.sum(y_pred[..., 0] * y_true[..., 1], axis = 1) / keras.ops.sum(y_pred[..., 0], axis = 1)\n",
    "    vwap_mkt = keras.ops.sum(y_true[..., 0] * y_true[..., 1], axis = 1) / keras.ops.sum(y_true[..., 0], axis = 1)\n",
    "    vwap_diff = vwap_achieved / vwap_mkt - 1.\n",
    "    loss = keras.ops.mean(keras.ops.square(vwap_diff))\n",
    "    return loss\n",
    "\n",
    "def absolute_vwap_loss(y_true, y_pred):\n",
    "    # Ensure all operations are done with float32\n",
    "    vwap_achieved = keras.ops.sum(y_pred[..., 0] * y_true[..., 1], axis = 1) / keras.ops.sum(y_pred[..., 0], axis = 1)\n",
    "    vwap_mkt = keras.ops.sum(y_true[..., 0] * y_true[..., 1], axis = 1) / keras.ops.sum(y_true[..., 0], axis = 1)\n",
    "    vwap_diff = vwap_achieved / vwap_mkt - 1.\n",
    "    loss = keras.ops.mean(keras.ops.abs(vwap_diff))\n",
    "    return loss\n",
    "\n",
    "def volume_curve_loss(y_true, y_pred):\n",
    "    # Ensure all operations are done with float32\n",
    "    volume_curve_achieved = y_pred[..., 0] / keras.ops.sum(y_pred[..., 0], axis = 1, keepdims=True)\n",
    "    volume_curve_mkt = y_true[..., 0] / keras.ops.sum(y_true[..., 0], axis = 1, keepdims=True)\n",
    "    volume_curve_diff = volume_curve_achieved - volume_curve_mkt\n",
    "    loss = keras.ops.mean(keras.ops.square(volume_curve_diff))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363eea7-be92-436a-a654-ab3618843792",
   "metadata": {},
   "source": [
    "# Static VWAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e2793-b0eb-4b1b-b48c-c37a90291d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable(name=\"StaticVWAP\")\n",
    "class StaticVWAP(Model):\n",
    "    def __init__(self, lookback, n_ahead, input_include_aheads = False, internal_model = None):\n",
    "        super(StaticVWAP, self).__init__()\n",
    "        self.lookback = lookback\n",
    "        self.n_ahead = n_ahead\n",
    "        self.input_include_aheads = input_include_aheads \n",
    "        self.internal_model = internal_model if internal_model is not None else TLN(output_len = n_ahead,\n",
    "                            output_features = 1,\n",
    "                            flatten_output = False,\n",
    "                            hidden_layers = 2,\n",
    "                            use_convolution = True,\n",
    "                            name = 'TLN')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, dict):\n",
    "            feature_shape = input_shape\n",
    "            self.dictionnary_input = True\n",
    "        else:\n",
    "            feature_shape = input_shape\n",
    "            self.dictionnary_input = False\n",
    "        internal_model_input_shape = (feature_shape[0], self.lookback, feature_shape[2])\n",
    "        internal_model_target_output_shape = (feature_shape[0], self.n_ahead, 1)\n",
    "        self.internal_model.build(internal_model_input_shape)\n",
    "        internal_model_output_shape = self.internal_model.compute_output_shape(internal_model_input_shape)\n",
    "        if internal_model_output_shape != internal_model_target_output_shape:\n",
    "            if (*internal_model_output_shape, 1) ==  internal_model_target_output_shape:\n",
    "                self.add_dims_to_internal_model = True\n",
    "            else:\n",
    "                raise ValueError(f\"\"\"internal model do not respect required output shape:\n",
    "                Received inputs shape {internal_model_input_shape} \n",
    "                Return outputs shape {internal_model_output_shape}\n",
    "                Required outputs shape {internal_model_target_output_shape}\n",
    "                \"\"\")\n",
    "        else:\n",
    "            self.add_dims_to_internal_model = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.dictionnary_input:\n",
    "            features = inputs\n",
    "        else:\n",
    "            features = inputs\n",
    "        if self.input_include_aheads:\n",
    "            features = keras.ops.slice(features, (0,0,0),(features.shape[0], self.lookback, features.shape[2]))\n",
    "        preds = self.internal_model(features)\n",
    "        if self.add_dims_to_internal_model:\n",
    "            preds = keras.ops.expand_dims(preds, axis=-1)\n",
    "        volume_curve = keras.ops.softmax(preds, axis=1)\n",
    "        results = keras.ops.concatenate([volume_curve, keras.ops.zeros_like(preds)], axis=-1)\n",
    "        return results\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'lookback': self.lookback,\n",
    "            'n_ahead': self.n_ahead,\n",
    "            'input_include_aheads': self.input_include_aheads,\n",
    "            'internal_model': {\n",
    "                'class_name': self.internal_model.__class__.__name__,\n",
    "                'config': self.internal_model.get_config()\n",
    "            }\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Extract internal model config\n",
    "        internal_model_config = config.pop('internal_model')\n",
    "        internal_model_class = globals()[internal_model_config['class_name']]\n",
    "        internal_model = internal_model_class.from_config(internal_model_config['config'])\n",
    "        \n",
    "        # Create new instance with remaining config\n",
    "        return cls(\n",
    "            lookback=config['lookback'],\n",
    "            n_ahead=config['n_ahead'],\n",
    "            input_include_aheads=config['input_include_aheads'],\n",
    "            internal_model=internal_model\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1f27a-4e5c-47db-b23d-ead4d2a39946",
   "metadata": {},
   "source": [
    "# Dynamic VWAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0787a48-a330-4fdc-bda6-e30dded72c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable(name=\"EqualInitializer\")\n",
    "class EqualInitializer(Initializer):\n",
    "    \"\"\"Initializes weights to 1/n_ahead.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_ahead):\n",
    "        self.n_ahead = n_ahead\n",
    "        \n",
    "    def __call__(self, shape, dtype=None):\n",
    "        return ops.ones(shape, dtype=dtype) / self.n_ahead\n",
    "\n",
    "        \n",
    "    def get_config(self):\n",
    "        return {'n_ahead': self.n_ahead}\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"PositiveSumToOneConstraint\")\n",
    "class PositiveSumToOneConstraint(keras.constraints.Constraint):\n",
    "    \"\"\"Constrains the weights to be positive and sum to 1.\"\"\"\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        # First ensure values are positive\n",
    "        w = keras.ops.maximum(w, 0)\n",
    "        # Then normalize to sum to 1\n",
    "        return w / (keras.ops.sum(w) + keras.backend.epsilon())\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"DynamicVWAP\")\n",
    "class DynamicVWAP(Model):\n",
    "    def __init__(self, lookback, n_ahead, hidden_size=100, hidden_rnn_layer=2, *args, **kwargs):\n",
    "        super(DynamicVWAP, self).__init__(*args, **kwargs)\n",
    "        self.lookback = lookback\n",
    "        self.n_ahead = n_ahead\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_rnn_layer = hidden_rnn_layer\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        feature_shape = input_shape\n",
    "        assert feature_shape[1] == self.lookback + self.n_ahead - 1\n",
    "        self.internal_rnn = Sequential([\n",
    "            TKAN(self.hidden_size, return_sequences=True)\n",
    "            for _ in range(self.hidden_rnn_layer)\n",
    "        ])\n",
    "        self.internal_rnn.build(feature_shape)    \n",
    "        internal_model_output_shape = self.internal_rnn.compute_output_shape(feature_shape)\n",
    "        self.internal_hidden_to_volume = [\n",
    "            Sequential([\n",
    "                Dense(self.hidden_size, activation='relu'),\n",
    "                Dense(self.hidden_size, activation='relu'),\n",
    "                Dense(1, activation='tanh') \n",
    "            ])\n",
    "            for _ in range(self.n_ahead - 1)\n",
    "        ]\n",
    "        for i in range(self.n_ahead - 1):\n",
    "            self.internal_hidden_to_volume[i].build((feature_shape[0], self.hidden_size + i))\n",
    "        self.base_volume_curve = self.add_weight(\n",
    "            shape=(self.n_ahead,),\n",
    "            name=\"base_curve\",\n",
    "            initializer=EqualInitializer(self.n_ahead),\n",
    "            constraint=PositiveSumToOneConstraint(),  # Using the new constraint\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        features = inputs\n",
    "        rnn_hidden = self.internal_rnn(features)\n",
    "        total_volume = ops.zeros((features.shape[0],1))\n",
    "        \n",
    "        for t in range(0, self.n_ahead - 1):\n",
    "            if t>0:\n",
    "                current_hidden = ops.concatenate([rnn_hidden[:, self.lookback + t, :], volume_curve], axis=1)\n",
    "            else:\n",
    "                current_hidden = rnn_hidden[:, self.lookback + t, :]\n",
    "            estimated_factor = 1. + self.internal_hidden_to_volume[t](current_hidden)\n",
    "            estimated_volume = self.base_volume_curve[t] * estimated_factor \n",
    "            estimated_volume = keras.ops.clip(estimated_volume, 0., 1. - total_volume)\n",
    "            total_volume += estimated_volume\n",
    "            if t==0:\n",
    "                volume_curve=estimated_volume\n",
    "            else:\n",
    "                volume_curve=ops.concatenate([volume_curve, estimated_volume], axis=1)\n",
    "            \n",
    "        estimated_volume=1. - total_volume\n",
    "        volume_curve=ops.concatenate([volume_curve, estimated_volume], axis=1)\n",
    "        volume_curve=ops.expand_dims(volume_curve, axis=2)\n",
    "        results = keras.ops.concatenate([volume_curve, keras.ops.zeros_like(volume_curve)], axis=-1)\n",
    "        return results\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'lookback': self.lookback,\n",
    "            'n_ahead': self.n_ahead,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'hidden_rnn_layer': self.hidden_rnn_layer,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 2, self.n_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc9c255-3e11-4a1a-8146-6826af820c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable(name=\"AddAndNorm\")\n",
    "class AddAndNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AddAndNorm, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.add_layer = Add()\n",
    "        self.add_layer.build(input_shape)\n",
    "        self.norm_layer = LayerNormalization()\n",
    "        self.norm_layer.build(self.add_layer.compute_output_shape(input_shape))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        tmp = self.add_layer(inputs)\n",
    "        tmp = self.norm_layer(tmp)\n",
    "        return tmp\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]  # Assuming all input shapes are the same\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"GRN\")\n",
    "class Gate(Layer):\n",
    "    def __init__(self, hidden_layer_size = None, **kwargs):\n",
    "        super(Gate, self).__init__(**kwargs)\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.hidden_layer_size is None:\n",
    "            self.hidden_layer_size = input_shape[-1]\n",
    "        self.dense_layer = Dense(self.hidden_layer_size)\n",
    "        self.gated_layer = Dense(self.hidden_layer_size, activation='sigmoid')\n",
    "        self.dense_layer.build(input_shape)\n",
    "        self.gated_layer.build(input_shape)\n",
    "        self.multiply = Multiply()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        dense_output = self.dense_layer(inputs)\n",
    "        gated_output = self.gated_layer(inputs)\n",
    "        return ops.multiply(dense_output, gated_output)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (self.hidden_layer_size,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'hidden_layer_size': self.hidden_layer_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"GRN\")\n",
    "class GRN(Layer):\n",
    "    def __init__(self, hidden_layer_size, output_size=None, **kwargs):\n",
    "        super(GRN, self).__init__(**kwargs)\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.output_size is None:\n",
    "            self.output_size = self.hidden_layer_size\n",
    "        self.skip_layer = Dense(self.output_size)\n",
    "        self.skip_layer.build(input_shape)\n",
    "        \n",
    "        self.hidden_layer_1 = Dense(self.hidden_layer_size, activation='elu')\n",
    "        self.hidden_layer_1.build(input_shape)\n",
    "        self.hidden_layer_2 = Dense(self.hidden_layer_size)\n",
    "        self.hidden_layer_2.build((*input_shape[:2], self.hidden_layer_size))\n",
    "        self.gate_layer = Gate(self.output_size)\n",
    "        self.gate_layer.build((*input_shape[:2], self.hidden_layer_size))\n",
    "        self.add_and_norm_layer = AddAndNorm()\n",
    "        self.add_and_norm_layer.build([(*input_shape[:2], self.output_size),(*input_shape[:2], self.output_size)])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        skip = self.skip_layer(inputs)\n",
    "        hidden = self.hidden_layer_1(inputs)\n",
    "        hidden = self.hidden_layer_2(hidden)\n",
    "        gating_output = self.gate_layer(hidden)\n",
    "        return self.add_and_norm_layer([skip, gating_output])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (self.output_size,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'hidden_layer_size': self.hidden_layer_size,\n",
    "            'output_size': self.output_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"VariableSelectionNetwork\")\n",
    "class VariableSelectionNetwork(Layer):\n",
    "    def __init__(self, num_hidden, **kwargs):\n",
    "        super(VariableSelectionNetwork, self).__init__(**kwargs)\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        batch_size, time_steps, embedding_dim, num_inputs = input_shape\n",
    "        self.softmax = Activation('softmax')\n",
    "        self.num_inputs = num_inputs\n",
    "        self.flatten_dim = time_steps * embedding_dim * num_inputs\n",
    "        self.reshape_layer = Reshape(target_shape=[time_steps, embedding_dim * num_inputs])\n",
    "        self.reshape_layer.build(input_shape)\n",
    "        self.mlp_dense = GRN(hidden_layer_size = self.num_hidden, output_size=num_inputs)\n",
    "        self.mlp_dense.build((batch_size, time_steps, embedding_dim * num_inputs))\n",
    "        self.grn_layers = [GRN(self.num_hidden) for _ in range(num_inputs)]\n",
    "        for i in range(num_inputs):\n",
    "            self.grn_layers[i].build(input_shape[:3])\n",
    "        super(VariableSelectionNetwork, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        _, time_steps, embedding_dim, num_inputs = inputs.shape\n",
    "        flatten = self.reshape_layer(inputs)\n",
    "        # Variable selection weights\n",
    "        mlp_outputs = self.mlp_dense(flatten)\n",
    "        sparse_weights = keras.activations.softmax(mlp_outputs)\n",
    "        sparse_weights = ops.expand_dims(sparse_weights, axis=2)\n",
    "        \n",
    "        # Non-linear Processing & weight application\n",
    "        trans_emb_list = []\n",
    "        for i in range(num_inputs):\n",
    "            grn_output = self.grn_layers[i](inputs[:, :, :, i])\n",
    "            trans_emb_list.append(grn_output)\n",
    "        \n",
    "        transformed_embedding = ops.stack(trans_emb_list, axis=-1)\n",
    "        combined = ops.multiply(sparse_weights, transformed_embedding)\n",
    "        temporal_ctx = ops.sum(combined, axis=-1)\n",
    "        \n",
    "        return temporal_ctx\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_hidden': self.num_hidden,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"EmbeddingLayer\")\n",
    "class EmbeddingLayer(Layer):\n",
    "    def __init__(self, num_hidden, **kwargs):\n",
    "        super(EmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_layers = [\n",
    "            Dense(self.num_hidden) for _ in range(input_shape[-1])\n",
    "        ]\n",
    "        for i in range(input_shape[-1]):\n",
    "            self.dense_layers[i].build((*input_shape[:2], 1))\n",
    "        super(EmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embeddings = [dense_layer(inputs[:, :, i:i+1]) for i, dense_layer in enumerate(self.dense_layers)]\n",
    "        return ops.stack(embeddings, axis=-1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return list(input_shape[:-1]) + [self.num_hidden, input_shape[-1]]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_hidden': self.num_hidden,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@keras.utils.register_keras_serializable(name=\"DynamicVWAPTransformer\")\n",
    "class DynamicVWAPTransformer(Model):\n",
    "    def __init__(self, lookback, n_ahead, hidden_size=100, hidden_rnn_layer=2, num_heads=3, num_embedding=3, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lookback = lookback\n",
    "        self.n_ahead = n_ahead\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_rnn_layer = hidden_rnn_layer\n",
    "        self.num_embedding = num_embedding\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        feature_shape = input_shape\n",
    "        assert feature_shape[1] == self.lookback + self.n_ahead - 1\n",
    "\n",
    "        self.embedding = EmbeddingLayer(self.num_embedding)\n",
    "        self.embedding.build(input_shape)\n",
    "        embedding_output_shape = self.embedding.compute_output_shape(input_shape)\n",
    "        self.vsn = VariableSelectionNetwork(self.hidden_size)\n",
    "        self.vsn.build(embedding_output_shape)\n",
    "        vsn_output_shape = (input_shape[0], input_shape[1], self.hidden_size)\n",
    "        \n",
    "        # RNN layers\n",
    "        self.internal_rnn = Sequential([\n",
    "            TKAN(self.hidden_size, return_sequences=True)\n",
    "            for _ in range(self.hidden_rnn_layer)\n",
    "        ])\n",
    "        self.internal_rnn.build(vsn_output_shape)\n",
    "        self.gate = Gate()\n",
    "        self.gate.build(vsn_output_shape)\n",
    "        self.addnorm = AddAndNorm()\n",
    "        self.addnorm.build([vsn_output_shape,vsn_output_shape])\n",
    "        self.grn = GRN(self.hidden_size)\n",
    "        self.grn.build(vsn_output_shape)\n",
    "        # Multi-head attention layer\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=self.hidden_size // self.num_heads,\n",
    "            value_dim=self.hidden_size // self.num_heads,\n",
    "            use_bias=True\n",
    "        )\n",
    "        self.attention.build(vsn_output_shape, vsn_output_shape, vsn_output_shape)#as the tkan do not changes shapes\n",
    "        \n",
    "        # Dense layers for volume prediction\n",
    "        self.internal_hidden_to_volume = [\n",
    "            Sequential([\n",
    "                Dense(self.hidden_size, activation='relu'),\n",
    "                Dense(self.hidden_size, activation='relu'),\n",
    "                Dense(1, activation='tanh')\n",
    "            ])\n",
    "            for _ in range(self.n_ahead - 1)\n",
    "        ]\n",
    "        \n",
    "        for i in range(self.n_ahead - 1):\n",
    "            self.internal_hidden_to_volume[i].build((feature_shape[0], self.hidden_size + i))\n",
    "            \n",
    "        # Base volume curve\n",
    "        self.base_volume_curve = self.add_weight(\n",
    "            shape=(self.n_ahead,),\n",
    "            name=\"base_curve\",\n",
    "            initializer=EqualInitializer(self.n_ahead),\n",
    "            constraint=PositiveSumToOneConstraint(),\n",
    "            trainable=True\n",
    "        )\n",
    "        super(DynamicVWAPTransformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        embedded_features = self.embedding(inputs)\n",
    "        selected = self.vsn(embedded_features)\n",
    "        # Get RNN hidden states\n",
    "        rnn_hidden = self.internal_rnn(selected)\n",
    "        all_context = self.addnorm([self.gate(rnn_hidden), selected])\n",
    "        enriched = self.grn(all_context)\n",
    "        \n",
    "        # Apply causal self-attention\n",
    "        attended_hidden = self.attention(\n",
    "            query=enriched,\n",
    "            value=enriched,\n",
    "            key=enriched,\n",
    "            use_causal_mask=True\n",
    "        )\n",
    "        \n",
    "        total_volume = ops.zeros((inputs.shape[0], 1))\n",
    "        \n",
    "        for t in range(0, self.n_ahead - 1):\n",
    "            if t > 0:\n",
    "                current_hidden = ops.concatenate([attended_hidden[:, self.lookback + t, :], volume_curve], axis=1)\n",
    "            else:\n",
    "                current_hidden = attended_hidden[:, self.lookback + t, :]\n",
    "                \n",
    "            estimated_factor = 1. + self.internal_hidden_to_volume[t](current_hidden)\n",
    "            estimated_volume = self.base_volume_curve[t] * estimated_factor\n",
    "            estimated_volume = keras.ops.clip(estimated_volume, 0., 1. - total_volume)\n",
    "            total_volume += estimated_volume\n",
    "            \n",
    "            if t == 0:\n",
    "                volume_curve = estimated_volume\n",
    "            else:\n",
    "                volume_curve = ops.concatenate([volume_curve, estimated_volume], axis=1)\n",
    "        \n",
    "        estimated_volume = 1. - total_volume\n",
    "        volume_curve = ops.concatenate([volume_curve, estimated_volume], axis=1)\n",
    "        volume_curve = ops.expand_dims(volume_curve, axis=2)\n",
    "        results = keras.ops.concatenate([volume_curve, keras.ops.zeros_like(volume_curve)], axis=-1)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'lookback': self.lookback,\n",
    "            'n_ahead': self.n_ahead,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'hidden_rnn_layer': self.hidden_rnn_layer,\n",
    "            'num_embedding': self.num_embedding,\n",
    "            'num_heads': self.num_heads\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 2, self.n_ahead)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d5636f-1efe-4681-be7b-a4d626b026f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable(name=\"DynamicSigVWAPTransformer\")\n",
    "class DynamicSigVWAPTransformer(Model):\n",
    "    def __init__(self, lookback, sig_lookback, n_ahead, hidden_size=100, \n",
    "                 hidden_rnn_layer=2, signature_depth=3, num_heads=3, *args, **kwargs):\n",
    "        super(DynamicSigVWAPTransformer, self).__init__(*args, **kwargs)\n",
    "        self.lookback = lookback\n",
    "        self.n_ahead = n_ahead\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_rnn_layer = hidden_rnn_layer\n",
    "        self.signature_depth = signature_depth\n",
    "        self.sig_lookback = sig_lookback\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert input_shape[1] == self.sig_lookback + self.n_ahead - 1\n",
    "        self.sig_layer_gate = SigLayer(depth=self.signature_depth, stream=False)\n",
    "        self.sig_layer_gate.build((input_shape[0], self.sig_lookback, 2))\n",
    "        self.sig_learnable_kernel = self.add_weight(\n",
    "            shape=(1, self.sig_lookback, 2),\n",
    "            name=\"sig_kernel\",\n",
    "            initializer=keras.initializers.Ones(),\n",
    "            trainable=True\n",
    "        )\n",
    "        sig_size = sum([2 ** i for i in range(1, self.signature_depth + 1)])\n",
    "        sig_output_shape = (input_shape[0], sig_size)\n",
    "        self.sig_to_weights = Sequential([\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.RepeatVector(self.lookback + self.n_ahead - 1),\n",
    "        ])\n",
    "        self.sig_to_weights.build(sig_output_shape)\n",
    "        vwap_input_shape = (input_shape[0], self.lookback + self.n_ahead - 1, input_shape[2]+sig_size)\n",
    "        self.dynamic_vwap = DynamicVWAPTransformer(self.lookback, self.n_ahead, hidden_size=self.hidden_size, hidden_rnn_layer=self.hidden_rnn_layer)\n",
    "        self.dynamic_vwap.build(vwap_input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        sig_features = self.sig_learnable_kernel * inputs[:,:self.sig_lookback,:2]\n",
    "        features = inputs[:,-self.lookback-self.n_ahead+1:]\n",
    "        signature_gate = self.sig_layer_gate(sig_features)\n",
    "        weights = self.sig_to_weights(signature_gate)\n",
    "        return self.dynamic_vwap(ops.concatenate([features, weights], axis=2))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'lookback': self.lookback,\n",
    "            'n_ahead': self.n_ahead,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'hidden_rnn_layer': self.hidden_rnn_layer,\n",
    "            'signature_depth': self.signature_depth,\n",
    "            'sig_lookback': self.sig_lookback,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 2, self.n_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e0c02-1506-43dc-86a3-e628f7d5f981",
   "metadata": {},
   "source": [
    "# Graph Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06842ac6-fa6d-485d-aa54-758aa916cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregated_pred_graph(name, n_ahead, preds, absolute_model_score, quadratic_model_score, r2_volume_curve):\n",
    "    # Set the style for a more academic look\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=1.2)\n",
    "    \n",
    "    # Create a DataFrame for easier plotting\n",
    "    df = pd.DataFrame(preds[:,:,0].T, columns=[f'Execution_{i+1}' for i in range(preds.shape[0])])\n",
    "    df['Period'] = range(1, n_ahead + 1)\n",
    "    df_melted = df.melt('Period', var_name='Execution', value_name='Allocation')\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Use a more subtle color palette\n",
    "    palette = sns.color_palette(\"Blues\", n_colors=preds.shape[0])\n",
    "    sns.lineplot(data=df_melted, x='Period', y='Allocation', hue='Execution', \n",
    "                 palette=palette, alpha=0.3, legend=False)\n",
    "    \n",
    "    # Calculate and plot the mean allocation\n",
    "    mean_allocation = df_melted.groupby('Period')['Allocation'].mean()\n",
    "    sns.lineplot(x=mean_allocation.index, y=mean_allocation.values, \n",
    "                 color='red', linewidth=2, label='Mean Allocation')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f'VWAP Execution Allocation per Period using {name} over {n_ahead} step', fontsize=16)\n",
    "    plt.xlabel('Period', fontsize=14)\n",
    "    plt.ylabel('Allocation', fontsize=14)\n",
    "    plt.ylim(0, df_melted['Allocation'].max() * 1.1)  # Set y-axis limit with some headroom\n",
    "    \n",
    "    # Add a legend\n",
    "    plt.legend(title='', loc='upper right', frameon=True)\n",
    "    \n",
    "    # Add text annotations for performance metrics\n",
    "    text = (f\"Abs. VWAP Loss (x1e2): {1e2*absolute_model_score:.4f}\\n\"\n",
    "            f\"Quad. VWAP Loss (x1e4): {1e4*quadratic_model_score:.4f}\\n\"\n",
    "            f\"Volume Curve R²: {r2_volume_curve:.4f}\")\n",
    "    plt.text(0.02, 0.98, text, transform=plt.gca().transAxes, \n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'vwap_execution_allocation_{name}_{n_ahead}_steps.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4087e-42b4-4da1-a47e-8e5f8cb57c40",
   "metadata": {},
   "source": [
    "# Full results generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4aa4f74-fc16-4b86-9224-76428b3d6c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n",
      "/tmp/ipykernel_388/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    }
   ],
   "source": [
    "def create_full_comparison(assets, train_assets, lookback, n_ahead, sig_lookback, verbose=True):\n",
    "\n",
    "    BATCH_SIZE = 128 * N_DEVICES\n",
    "    results = {}\n",
    "    loaded_model = {}\n",
    "    optimization_function = absolute_vwap_loss\n",
    "    for target_asset in assets:\n",
    "        for model_type in [\"Naive\", 'Globally Fitted DynamicVWAP Transformer']:\n",
    "\n",
    "            if model_type not in loaded_model:\n",
    "                loaded_model[model_type] = {}\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = full_generate(target_asset, lookback=sig_lookback, n_ahead=n_ahead, include_ahead_inputs = True)\n",
    "\n",
    "            val_size = int(len(X_train) * validation_split)\n",
    "            X_val = X_train[-val_size:]\n",
    "            y_val = y_train[-val_size:]\n",
    "            X_train = X_train[:-val_size]\n",
    "            y_train = y_train[:-val_size]\n",
    "            \n",
    "            val_samples = X_val.shape[0]\n",
    "            val_batches = val_samples // BATCH_SIZE\n",
    "            val_samples_adjusted = val_batches * BATCH_SIZE\n",
    "            X_val = X_val[:val_samples_adjusted]\n",
    "            y_val = y_val[:val_samples_adjusted]\n",
    "            \n",
    "            train_samples = X_train.shape[0]\n",
    "            train_batches = train_samples // BATCH_SIZE\n",
    "            train_samples_adjusted = train_batches * BATCH_SIZE\n",
    "            X_train = X_train[:train_samples_adjusted]\n",
    "            y_train = y_train[:train_samples_adjusted]\n",
    "\n",
    "            results_absolute = []\n",
    "            results_quadratic = []\n",
    "            results_volume_curve_r2 = []\n",
    "            training_times = []\n",
    "            all_preds = np.zeros((y_test.shape[0] * N_RUNS, *y_test.shape[1:]))\n",
    "            for run in range(N_RUNS):\n",
    "                training_time = 0\n",
    "                data_parallel = keras.distribution.DataParallel()\n",
    "                keras.distribution.set_distribution(data_parallel)\n",
    "                if model_type=='Globally Fitted DynamicVWAP Transformer':\n",
    "                    keras.distribution.set_distribution(None)\n",
    "                    if run not in loaded_model[model_type]:\n",
    "                        loaded_model[model_type][run] = keras.models.load_model(f'base_dynamic_transformer_model_200_{run}.keras', compile=False)\n",
    "\n",
    "                    model = loaded_model[model_type][run]\n",
    "                    \n",
    "                    naive_preds = np.copy(y_test)\n",
    "                    naive_preds[:,:,0] = 1/n_ahead\n",
    "                    preds = model.predict(X_test, verbose=False)\n",
    "                    \n",
    "                    absolute_model_score = absolute_vwap_loss(y_test, preds)\n",
    "                    quadratic_model_score = quadratic_vwap_loss(y_test, preds)\n",
    "                    r2_volume_curve = r2_score(y_true=(y_test[:,:,0] / np.sum(y_test[:,:,0], axis=1, keepdims=True)).flatten(), \n",
    "                                               y_pred=preds[:,:,0].flatten())\n",
    "                elif model_type=='Naive':\n",
    "                    if optimization_function!=absolute_vwap_loss or run!=0:\n",
    "                        break\n",
    "                    model = None\n",
    "                    training_time = 0\n",
    "                    preds = np.copy(y_test)\n",
    "                    preds[:,:,0] = 1./n_ahead\n",
    "                    absolute_model_score = absolute_vwap_loss(y_test, preds)\n",
    "                    quadratic_model_score = quadratic_vwap_loss(y_test, preds)\n",
    "                    r2_volume_curve = r2_score(y_true=(y_test[:,:,0] / np.sum(y_test[:,:,0], axis=1, keepdims=True)).flatten(), y_pred=preds[:,:,0].flatten())\n",
    "                \n",
    "                else:\n",
    "                    raise ValueError\n",
    "                \n",
    "                all_preds[run * y_test.shape[0]:(run + 1) * y_test.shape[0]] = preds\n",
    "                results_absolute.append(absolute_model_score)\n",
    "                results_quadratic.append(quadratic_model_score)\n",
    "                results_volume_curve_r2.append(r2_volume_curve)\n",
    "                training_times.append(training_time)\n",
    "                \n",
    "                del model\n",
    "    \n",
    "            if model_type not in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] and optimization_function!=absolute_vwap_loss:\n",
    "                continue\n",
    "            if model_type == 'Naive':\n",
    "                all_preds = all_preds[:y_test.shape[0]]\n",
    "                \n",
    "\n",
    "            opt_function_name = optimization_function.__name__\n",
    "\n",
    "            name = f'{model_type} {\"using \" + opt_function_name if model_type in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] else \"\"}: {target_asset}'\n",
    "            #create_aggregated_pred_graph(name, n_ahead, all_preds , absolute_model_score, quadratic_model_score, r2_volume_curve)\n",
    "            \n",
    "            results_absolute = np.array(results_absolute) *1e2\n",
    "            results_quadratic = np.array(results_quadratic) *1e4\n",
    "            results_volume_curve_r2 = np.array(results_volume_curve_r2)\n",
    "            \n",
    "            results[f'{model_type}_{target_asset}_{opt_function_name}'] = {\n",
    "                \"model type\": model_type,\n",
    "                \"asset\": target_asset,\n",
    "                \"Training Asset\": target_asset in train_assets, \n",
    "                \"optimization_function\": opt_function_name if model_type in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] else \"N/A\",\n",
    "                \"mean_absolute_vwap_loss\": np.mean(results_absolute),\n",
    "                \"std_absolute_vwap_loss\": np.std(results_absolute) if model_type in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] else 0,\n",
    "                \"mean_quadratic_vwap_loss\": np.mean(results_quadratic),\n",
    "                \"std_quadratic_vwap_loss\": np.std(results_quadratic) if model_type in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] else 0,\n",
    "                \"mean_r2_volume_curve\": np.mean(results_volume_curve_r2),\n",
    "                \"std_r2_volume_curve\": np.std(results_volume_curve_r2) if model_type in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] else 0,\n",
    "                \"mean_training_time\": np.mean(training_times),\n",
    "                \"std_training_time\": np.std(training_times) if model_type in [\"Asset Fitted DynamicVWAP\", \"Asset Fitted DynamicSigVWAP\",\"Globally Fitted DynamicVWAP Transformer\", \"Globally Fitted DynamicSigVWAP\"] else 0,\n",
    "            }\n",
    "            if verbose:\n",
    "                print(\"Is Train asset: \", target_asset in train_assets)\n",
    "                print(f\"{model_type}_{target_asset}_{opt_function_name}: Mean Training time: {np.mean(training_times):.4f} (±{np.std(training_times):.4f})\")\n",
    "                print(f\"{model_type}_{target_asset}_{opt_function_name}: Mean absolute VWAP loss (1e-2): {np.mean(results_absolute):.4f} (±{np.std(results_absolute):.4f})\")\n",
    "                print(f\"{model_type}_{target_asset}_{opt_function_name}: Mean quadratic VWAP loss (1e-4): {np.mean(results_quadratic):.4f} (±{np.std(results_quadratic):.4f})\")\n",
    "                print(f\"{model_type}_{target_asset}_{opt_function_name}: Mean R2 on volume curve: {np.mean(results_volume_curve_r2):.4f} (±{np.std(results_volume_curve_r2):.4f})\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results.values())\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "data_parallel = keras.distribution.DataParallel()\n",
    "keras.distribution.set_distribution(data_parallel)\n",
    "BATCH_SIZE = 512 * N_DEVICES\n",
    "lookback = 60\n",
    "sig_lookback = 400\n",
    "n_ahead = 12\n",
    "validation_split = 0.2\n",
    "\n",
    "optimization_function = absolute_vwap_loss\n",
    "full_X_train = None\n",
    "for asset in train_assets:\n",
    "    X_train, X_test, y_train, y_test = full_generate(asset, lookback=sig_lookback, n_ahead=n_ahead, include_ahead_inputs = True)\n",
    "    val_size = int(len(X_train) * validation_split)\n",
    "    X_val = X_train[-val_size:]\n",
    "    y_val = y_train[-val_size:]\n",
    "    X_train = X_train[:-val_size]\n",
    "    y_train = y_train[:-val_size]\n",
    "    if full_X_train is None:\n",
    "        full_X_train = X_train\n",
    "        full_X_val = X_val\n",
    "        full_X_test = X_test\n",
    "        full_y_train = y_train\n",
    "        full_y_val = y_val\n",
    "        full_y_test = y_test\n",
    "    else:\n",
    "        full_X_train = np.concatenate([full_X_train, X_train], axis=0)\n",
    "        full_y_train = np.concatenate([full_y_train, y_train], axis=0)\n",
    "        full_y_val = np.concatenate([full_y_val, y_val], axis=0)\n",
    "        full_y_test = np.concatenate([full_y_test, y_test], axis=0)\n",
    "\n",
    "val_samples = full_X_val.shape[0]\n",
    "val_batches = val_samples // BATCH_SIZE\n",
    "val_samples_adjusted = val_batches * BATCH_SIZE\n",
    "full_X_val = full_X_val[:val_samples_adjusted]\n",
    "full_y_val = full_y_val[:val_samples_adjusted]\n",
    "\n",
    "\n",
    "train_samples = full_X_train.shape[0]\n",
    "train_batches = train_samples // BATCH_SIZE\n",
    "train_samples_adjusted = train_batches * BATCH_SIZE\n",
    "full_X_train = full_X_train[:train_samples_adjusted]\n",
    "full_y_train = full_y_train[:train_samples_adjusted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d95de81-44a0-497b-9bf2-0f1f07731f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do run 0\n",
      "do run 1\n",
      "Epoch 1/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 147ms/step - loss: 0.0032 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0031 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0030 - val_loss: 0.0010 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0029 - val_loss: 0.0010 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0029 - val_loss: 9.9435e-04 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0028 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0028 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0027 - val_loss: 9.6235e-04 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0026 - val_loss: 9.3761e-04 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0024 - val_loss: 9.7672e-04 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0023 - val_loss: 9.6588e-04 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0022 - val_loss: 9.2940e-04 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0021 - val_loss: 8.6420e-04 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0021 - val_loss: 9.2731e-04 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0020 - val_loss: 8.7797e-04 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0019 - val_loss: 8.5681e-04 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0018 - val_loss: 8.9436e-04 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0018 - val_loss: 8.7258e-04 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0017 - val_loss: 9.1080e-04 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0015 - val_loss: 8.9082e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0014 - val_loss: 9.1127e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0014 - val_loss: 9.2532e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0013 - val_loss: 9.2742e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0013 - val_loss: 9.1147e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0013 - val_loss: 9.3003e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0012 - val_loss: 9.2890e-04 - learning_rate: 6.2500e-05\n",
      "do run 2\n",
      "Epoch 1/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 147ms/step - loss: 0.0032 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0031 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0030 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0029 - val_loss: 9.7430e-04 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0028 - val_loss: 9.3158e-04 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0027 - val_loss: 9.4933e-04 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0026 - val_loss: 9.6949e-04 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0024 - val_loss: 8.6359e-04 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0023 - val_loss: 8.7325e-04 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 130ms/step - loss: 0.0022 - val_loss: 8.8758e-04 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 130ms/step - loss: 0.0021 - val_loss: 8.9639e-04 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0020 - val_loss: 8.6496e-04 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0019 - val_loss: 8.4047e-04 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0018 - val_loss: 9.8469e-04 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0018 - val_loss: 8.9302e-04 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0017 - val_loss: 8.8469e-04 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0016 - val_loss: 9.1056e-04 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0016 - val_loss: 8.9593e-04 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 8.7975e-04 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0013 - val_loss: 8.6850e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0012 - val_loss: 8.5917e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0012 - val_loss: 9.0713e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 131ms/step - loss: 0.0012 - val_loss: 8.6740e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0011 - val_loss: 8.9004e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0011 - val_loss: 9.0293e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 132ms/step - loss: 0.0010 - val_loss: 8.9360e-04 - learning_rate: 6.2500e-05\n",
      "mean train_times_dynamic nan std nan\n",
      "mean train_times_dynamic 3059.366199851036 std 55.6490820646286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "data_parallel = keras.distribution.DataParallel()\n",
    "keras.distribution.set_distribution(data_parallel)\n",
    "\n",
    "train_times_dynamic=[]\n",
    "train_times_dynamic_sig=[]\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    print('do run', run)\n",
    "\n",
    "    if not os.path.exists(f'base_dynamic_transformer_model_200_{run}.keras'):\n",
    "        base_dynamic_sig_model = DynamicSigVWAPTransformer(lookback=lookback, sig_lookback=sig_lookback, n_ahead=n_ahead, hidden_size=200)\n",
    "        base_dynamic_sig_model.compile(optimizer='adam', loss=optimization_function)\n",
    "        t1=time.time()\n",
    "        history = base_dynamic_sig_model.fit(full_X_train, full_y_train, batch_size=BATCH_SIZE, epochs=N_MAX_EPOCHS, \n",
    "                            validation_data=(full_X_val, full_y_val), callbacks=callbacks(), shuffle=True, verbose=True)\n",
    "        train_times_dynamic_sig.append(time.time()-t1)\n",
    "        base_dynamic_sig_model.save(f'base_dynamic_transformer_model_200_{run}.keras')\n",
    "        del base_dynamic_sig_model\n",
    "\n",
    "\n",
    "print('mean train_times_dynamic', np.mean(train_times_dynamic), 'std', np.std(train_times_dynamic))\n",
    "print('mean train_times_dynamic', np.mean(train_times_dynamic_sig), 'std', np.std(train_times_dynamic_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0263985f-8784-450f-9277-c5048a8a458b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_BTC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BTC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1600 (±0.0000)\n",
      "Naive_BTC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0889 (±0.0000)\n",
      "Naive_BTC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n",
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_BTC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BTC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1032 (±0.0003)\n",
      "Globally Fitted DynamicVWAP Transformer_BTC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0370 (±0.0014)\n",
      "Globally Fitted DynamicVWAP Transformer_BTC_absolute_vwap_loss: Mean R2 on volume curve: -0.3817 (±0.0718)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ETH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ETH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1791 (±0.0000)\n",
      "Naive_ETH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1176 (±0.0000)\n",
      "Naive_ETH_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ETH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ETH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1142 (±0.0021)\n",
      "Globally Fitted DynamicVWAP Transformer_ETH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0506 (±0.0033)\n",
      "Globally Fitted DynamicVWAP Transformer_ETH_absolute_vwap_loss: Mean R2 on volume curve: -0.4487 (±0.0519)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_BCH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BCH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2959 (±0.0000)\n",
      "Naive_BCH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3829 (±0.0000)\n",
      "Naive_BCH_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_BCH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BCH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2142 (±0.0034)\n",
      "Globally Fitted DynamicVWAP Transformer_BCH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1884 (±0.0103)\n",
      "Globally Fitted DynamicVWAP Transformer_BCH_absolute_vwap_loss: Mean R2 on volume curve: -0.4595 (±0.0371)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_XRP_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_XRP_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2179 (±0.0000)\n",
      "Naive_XRP_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2507 (±0.0000)\n",
      "Naive_XRP_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_XRP_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_XRP_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1611 (±0.0015)\n",
      "Globally Fitted DynamicVWAP Transformer_XRP_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1508 (±0.0121)\n",
      "Globally Fitted DynamicVWAP Transformer_XRP_absolute_vwap_loss: Mean R2 on volume curve: -0.5105 (±0.0475)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_EOS_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_EOS_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2293 (±0.0000)\n",
      "Naive_EOS_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2576 (±0.0000)\n",
      "Naive_EOS_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_EOS_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_EOS_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1812 (±0.0026)\n",
      "Globally Fitted DynamicVWAP Transformer_EOS_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1955 (±0.0109)\n",
      "Globally Fitted DynamicVWAP Transformer_EOS_absolute_vwap_loss: Mean R2 on volume curve: -0.5415 (±0.0458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_LTC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_LTC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1948 (±0.0000)\n",
      "Naive_LTC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1722 (±0.0000)\n",
      "Naive_LTC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_LTC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_LTC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1438 (±0.0033)\n",
      "Globally Fitted DynamicVWAP Transformer_LTC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0819 (±0.0076)\n",
      "Globally Fitted DynamicVWAP Transformer_LTC_absolute_vwap_loss: Mean R2 on volume curve: -0.5179 (±0.0520)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_TRX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_TRX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1033 (±0.0000)\n",
      "Naive_TRX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0598 (±0.0000)\n",
      "Naive_TRX_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_TRX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_TRX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.0827 (±0.0006)\n",
      "Globally Fitted DynamicVWAP Transformer_TRX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0310 (±0.0019)\n",
      "Globally Fitted DynamicVWAP Transformer_TRX_absolute_vwap_loss: Mean R2 on volume curve: -0.4358 (±0.0608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ETC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ETC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2609 (±0.0000)\n",
      "Naive_ETC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2965 (±0.0000)\n",
      "Naive_ETC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ETC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ETC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1861 (±0.0049)\n",
      "Globally Fitted DynamicVWAP Transformer_ETC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1485 (±0.0205)\n",
      "Globally Fitted DynamicVWAP Transformer_ETC_absolute_vwap_loss: Mean R2 on volume curve: -0.4733 (±0.0445)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_LINK_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_LINK_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2445 (±0.0000)\n",
      "Naive_LINK_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2838 (±0.0000)\n",
      "Naive_LINK_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_LINK_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_LINK_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1807 (±0.0050)\n",
      "Globally Fitted DynamicVWAP Transformer_LINK_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1599 (±0.0324)\n",
      "Globally Fitted DynamicVWAP Transformer_LINK_absolute_vwap_loss: Mean R2 on volume curve: -0.6697 (±0.0243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_XLM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_XLM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1915 (±0.0000)\n",
      "Naive_XLM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1857 (±0.0000)\n",
      "Naive_XLM_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_XLM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_XLM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1495 (±0.0021)\n",
      "Globally Fitted DynamicVWAP Transformer_XLM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1046 (±0.0063)\n",
      "Globally Fitted DynamicVWAP Transformer_XLM_absolute_vwap_loss: Mean R2 on volume curve: -0.5354 (±0.0412)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_ADA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ADA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2272 (±0.0000)\n",
      "Naive_ADA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2315 (±0.0000)\n",
      "Naive_ADA_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_ADA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ADA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1654 (±0.0038)\n",
      "Globally Fitted DynamicVWAP Transformer_ADA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1348 (±0.0174)\n",
      "Globally Fitted DynamicVWAP Transformer_ADA_absolute_vwap_loss: Mean R2 on volume curve: -0.5800 (±0.0334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_XMR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_XMR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1477 (±0.0000)\n",
      "Naive_XMR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2252 (±0.0000)\n",
      "Naive_XMR_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_XMR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_XMR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1417 (±0.0013)\n",
      "Globally Fitted DynamicVWAP Transformer_XMR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3863 (±0.0088)\n",
      "Globally Fitted DynamicVWAP Transformer_XMR_absolute_vwap_loss: Mean R2 on volume curve: -0.7540 (±0.0604)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_DASH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_DASH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2041 (±0.0000)\n",
      "Naive_DASH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2261 (±0.0000)\n",
      "Naive_DASH_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_DASH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_DASH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1589 (±0.0040)\n",
      "Globally Fitted DynamicVWAP Transformer_DASH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1338 (±0.0119)\n",
      "Globally Fitted DynamicVWAP Transformer_DASH_absolute_vwap_loss: Mean R2 on volume curve: -0.5909 (±0.0365)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ZEC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ZEC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2274 (±0.0000)\n",
      "Naive_ZEC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2947 (±0.0000)\n",
      "Naive_ZEC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ZEC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ZEC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1835 (±0.0053)\n",
      "Globally Fitted DynamicVWAP Transformer_ZEC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1800 (±0.0272)\n",
      "Globally Fitted DynamicVWAP Transformer_ZEC_absolute_vwap_loss: Mean R2 on volume curve: -0.6232 (±0.0435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_XTZ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_XTZ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2414 (±0.0000)\n",
      "Naive_XTZ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3010 (±0.0000)\n",
      "Naive_XTZ_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_XTZ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_XTZ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1959 (±0.0018)\n",
      "Globally Fitted DynamicVWAP Transformer_XTZ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1689 (±0.0082)\n",
      "Globally Fitted DynamicVWAP Transformer_XTZ_absolute_vwap_loss: Mean R2 on volume curve: -0.4153 (±0.0426)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ATOM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ATOM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2113 (±0.0000)\n",
      "Naive_ATOM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1804 (±0.0000)\n",
      "Naive_ATOM_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ATOM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ATOM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1624 (±0.0039)\n",
      "Globally Fitted DynamicVWAP Transformer_ATOM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1065 (±0.0129)\n",
      "Globally Fitted DynamicVWAP Transformer_ATOM_absolute_vwap_loss: Mean R2 on volume curve: -0.6141 (±0.0287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_BNB_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BNB_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1739 (±0.0000)\n",
      "Naive_BNB_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1192 (±0.0000)\n",
      "Naive_BNB_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_BNB_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BNB_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1242 (±0.0009)\n",
      "Globally Fitted DynamicVWAP Transformer_BNB_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.0590 (±0.0014)\n",
      "Globally Fitted DynamicVWAP Transformer_BNB_absolute_vwap_loss: Mean R2 on volume curve: -0.4754 (±0.0510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ONT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ONT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3347 (±0.0000)\n",
      "Naive_ONT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5109 (±0.0000)\n",
      "Naive_ONT_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ONT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ONT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2632 (±0.0027)\n",
      "Globally Fitted DynamicVWAP Transformer_ONT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3256 (±0.0227)\n",
      "Globally Fitted DynamicVWAP Transformer_ONT_absolute_vwap_loss: Mean R2 on volume curve: -0.3678 (±0.0575)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_IOTA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_IOTA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3229 (±0.0000)\n",
      "Naive_IOTA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6238 (±0.0000)\n",
      "Naive_IOTA_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_IOTA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_IOTA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2632 (±0.0055)\n",
      "Globally Fitted DynamicVWAP Transformer_IOTA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4129 (±0.0211)\n",
      "Globally Fitted DynamicVWAP Transformer_IOTA_absolute_vwap_loss: Mean R2 on volume curve: -0.4819 (±0.0415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_BAT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BAT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2533 (±0.0000)\n",
      "Naive_BAT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2880 (±0.0000)\n",
      "Naive_BAT_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_BAT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BAT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2203 (±0.0048)\n",
      "Globally Fitted DynamicVWAP Transformer_BAT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2252 (±0.0182)\n",
      "Globally Fitted DynamicVWAP Transformer_BAT_absolute_vwap_loss: Mean R2 on volume curve: -0.3988 (±0.0327)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_VET_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_VET_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2663 (±0.0000)\n",
      "Naive_VET_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3139 (±0.0000)\n",
      "Naive_VET_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_VET_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_VET_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2041 (±0.0024)\n",
      "Globally Fitted DynamicVWAP Transformer_VET_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1800 (±0.0100)\n",
      "Globally Fitted DynamicVWAP Transformer_VET_absolute_vwap_loss: Mean R2 on volume curve: -0.4936 (±0.0467)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_NEO_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_NEO_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3084 (±0.0000)\n",
      "Naive_NEO_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5270 (±0.0000)\n",
      "Naive_NEO_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_NEO_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_NEO_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2408 (±0.0027)\n",
      "Globally Fitted DynamicVWAP Transformer_NEO_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3437 (±0.0077)\n",
      "Globally Fitted DynamicVWAP Transformer_NEO_absolute_vwap_loss: Mean R2 on volume curve: -0.4829 (±0.0528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_QTUM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_QTUM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3065 (±0.0000)\n",
      "Naive_QTUM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5235 (±0.0000)\n",
      "Naive_QTUM_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_QTUM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_QTUM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2421 (±0.0030)\n",
      "Globally Fitted DynamicVWAP Transformer_QTUM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3253 (±0.0385)\n",
      "Globally Fitted DynamicVWAP Transformer_QTUM_absolute_vwap_loss: Mean R2 on volume curve: -0.3788 (±0.0537)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_IOST_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_IOST_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2681 (±0.0000)\n",
      "Naive_IOST_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3690 (±0.0000)\n",
      "Naive_IOST_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_IOST_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_IOST_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2169 (±0.0026)\n",
      "Globally Fitted DynamicVWAP Transformer_IOST_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2400 (±0.0109)\n",
      "Globally Fitted DynamicVWAP Transformer_IOST_absolute_vwap_loss: Mean R2 on volume curve: -0.3560 (±0.0497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_THETA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_THETA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3352 (±0.0000)\n",
      "Naive_THETA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5155 (±0.0000)\n",
      "Naive_THETA_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_THETA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_THETA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2621 (±0.0068)\n",
      "Globally Fitted DynamicVWAP Transformer_THETA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3343 (±0.0267)\n",
      "Globally Fitted DynamicVWAP Transformer_THETA_absolute_vwap_loss: Mean R2 on volume curve: -0.5052 (±0.0589)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ALGO_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ALGO_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2762 (±0.0000)\n",
      "Naive_ALGO_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3729 (±0.0000)\n",
      "Naive_ALGO_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ALGO_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ALGO_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2099 (±0.0055)\n",
      "Globally Fitted DynamicVWAP Transformer_ALGO_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2083 (±0.0237)\n",
      "Globally Fitted DynamicVWAP Transformer_ALGO_absolute_vwap_loss: Mean R2 on volume curve: -0.6382 (±0.0405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_ZIL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ZIL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2802 (±0.0000)\n",
      "Naive_ZIL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3757 (±0.0000)\n",
      "Naive_ZIL_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_ZIL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ZIL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2180 (±0.0027)\n",
      "Globally Fitted DynamicVWAP Transformer_ZIL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2371 (±0.0275)\n",
      "Globally Fitted DynamicVWAP Transformer_ZIL_absolute_vwap_loss: Mean R2 on volume curve: -0.4589 (±0.0584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_KNC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_KNC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2700 (±0.0000)\n",
      "Naive_KNC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3287 (±0.0000)\n",
      "Naive_KNC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_KNC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_KNC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2216 (±0.0045)\n",
      "Globally Fitted DynamicVWAP Transformer_KNC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2124 (±0.0415)\n",
      "Globally Fitted DynamicVWAP Transformer_KNC_absolute_vwap_loss: Mean R2 on volume curve: -0.4612 (±0.0437)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_ZRX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ZRX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4219 (±0.0000)\n",
      "Naive_ZRX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.9514 (±0.0000)\n",
      "Naive_ZRX_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_ZRX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ZRX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3555 (±0.0063)\n",
      "Globally Fitted DynamicVWAP Transformer_ZRX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7120 (±0.0906)\n",
      "Globally Fitted DynamicVWAP Transformer_ZRX_absolute_vwap_loss: Mean R2 on volume curve: -0.4575 (±0.0583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_COMP_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_COMP_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2907 (±0.0000)\n",
      "Naive_COMP_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4285 (±0.0000)\n",
      "Naive_COMP_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_COMP_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_COMP_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2214 (±0.0036)\n",
      "Globally Fitted DynamicVWAP Transformer_COMP_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2644 (±0.0198)\n",
      "Globally Fitted DynamicVWAP Transformer_COMP_absolute_vwap_loss: Mean R2 on volume curve: -0.5210 (±0.0490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_OMG_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_OMG_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3762 (±0.0000)\n",
      "Naive_OMG_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.9917 (±0.0000)\n",
      "Naive_OMG_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_OMG_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_OMG_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3166 (±0.0049)\n",
      "Globally Fitted DynamicVWAP Transformer_OMG_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7672 (±0.0261)\n",
      "Globally Fitted DynamicVWAP Transformer_OMG_absolute_vwap_loss: Mean R2 on volume curve: -0.5613 (±0.0379)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_DOGE_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_DOGE_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2849 (±0.0000)\n",
      "Naive_DOGE_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3377 (±0.0000)\n",
      "Naive_DOGE_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_DOGE_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_DOGE_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2051 (±0.0041)\n",
      "Globally Fitted DynamicVWAP Transformer_DOGE_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1910 (±0.0208)\n",
      "Globally Fitted DynamicVWAP Transformer_DOGE_absolute_vwap_loss: Mean R2 on volume curve: -0.5606 (±0.0471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_SXP_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_SXP_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2916 (±0.0000)\n",
      "Naive_SXP_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3894 (±0.0000)\n",
      "Naive_SXP_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_SXP_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_SXP_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2354 (±0.0072)\n",
      "Globally Fitted DynamicVWAP Transformer_SXP_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2756 (±0.0401)\n",
      "Globally Fitted DynamicVWAP Transformer_SXP_absolute_vwap_loss: Mean R2 on volume curve: -0.4259 (±0.0585)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_KAVA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_KAVA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2341 (±0.0000)\n",
      "Naive_KAVA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2461 (±0.0000)\n",
      "Naive_KAVA_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_KAVA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_KAVA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1894 (±0.0027)\n",
      "Globally Fitted DynamicVWAP Transformer_KAVA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1736 (±0.0192)\n",
      "Globally Fitted DynamicVWAP Transformer_KAVA_absolute_vwap_loss: Mean R2 on volume curve: -0.4226 (±0.0361)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_BAND_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BAND_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3498 (±0.0000)\n",
      "Naive_BAND_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7071 (±0.0000)\n",
      "Naive_BAND_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_BAND_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BAND_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2911 (±0.0067)\n",
      "Globally Fitted DynamicVWAP Transformer_BAND_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5212 (±0.0482)\n",
      "Globally Fitted DynamicVWAP Transformer_BAND_absolute_vwap_loss: Mean R2 on volume curve: -0.5489 (±0.0509)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_RLC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_RLC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3773 (±0.0000)\n",
      "Naive_RLC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7005 (±0.0000)\n",
      "Naive_RLC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_RLC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_RLC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3030 (±0.0066)\n",
      "Globally Fitted DynamicVWAP Transformer_RLC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4329 (±0.0382)\n",
      "Globally Fitted DynamicVWAP Transformer_RLC_absolute_vwap_loss: Mean R2 on volume curve: -0.5566 (±0.0522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_MKR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_MKR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2373 (±0.0000)\n",
      "Naive_MKR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2858 (±0.0000)\n",
      "Naive_MKR_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_MKR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_MKR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1882 (±0.0028)\n",
      "Globally Fitted DynamicVWAP Transformer_MKR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1787 (±0.0116)\n",
      "Globally Fitted DynamicVWAP Transformer_MKR_absolute_vwap_loss: Mean R2 on volume curve: -0.5728 (±0.0300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_SNX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_SNX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3011 (±0.0000)\n",
      "Naive_SNX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3573 (±0.0000)\n",
      "Naive_SNX_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_SNX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_SNX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2248 (±0.0065)\n",
      "Globally Fitted DynamicVWAP Transformer_SNX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2029 (±0.0281)\n",
      "Globally Fitted DynamicVWAP Transformer_SNX_absolute_vwap_loss: Mean R2 on volume curve: -0.5559 (±0.0558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_DOT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_DOT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2482 (±0.0000)\n",
      "Naive_DOT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2854 (±0.0000)\n",
      "Naive_DOT_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_DOT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_DOT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1825 (±0.0079)\n",
      "Globally Fitted DynamicVWAP Transformer_DOT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1548 (±0.0252)\n",
      "Globally Fitted DynamicVWAP Transformer_DOT_absolute_vwap_loss: Mean R2 on volume curve: -0.6090 (±0.0319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_DEFI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_DEFI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2702 (±0.0000)\n",
      "Naive_DEFI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4043 (±0.0000)\n",
      "Naive_DEFI_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_DEFI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_DEFI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2126 (±0.0070)\n",
      "Globally Fitted DynamicVWAP Transformer_DEFI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2545 (±0.0260)\n",
      "Globally Fitted DynamicVWAP Transformer_DEFI_absolute_vwap_loss: Mean R2 on volume curve: -0.3384 (±0.0482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_YFI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_YFI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2947 (±0.0000)\n",
      "Naive_YFI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.9019 (±0.0000)\n",
      "Naive_YFI_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_YFI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_YFI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2336 (±0.0061)\n",
      "Globally Fitted DynamicVWAP Transformer_YFI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6459 (±0.1084)\n",
      "Globally Fitted DynamicVWAP Transformer_YFI_absolute_vwap_loss: Mean R2 on volume curve: -0.4987 (±0.0602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_BAL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BAL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2243 (±0.0000)\n",
      "Naive_BAL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2475 (±0.0000)\n",
      "Naive_BAL_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_BAL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BAL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1774 (±0.0047)\n",
      "Globally Fitted DynamicVWAP Transformer_BAL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1456 (±0.0197)\n",
      "Globally Fitted DynamicVWAP Transformer_BAL_absolute_vwap_loss: Mean R2 on volume curve: -0.5187 (±0.0611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_CRV_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_CRV_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2866 (±0.0000)\n",
      "Naive_CRV_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.8299 (±0.0000)\n",
      "Naive_CRV_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_CRV_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_CRV_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2320 (±0.0106)\n",
      "Globally Fitted DynamicVWAP Transformer_CRV_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6222 (±0.1131)\n",
      "Globally Fitted DynamicVWAP Transformer_CRV_absolute_vwap_loss: Mean R2 on volume curve: -0.6573 (±0.0376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_WAVES_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_WAVES_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3630 (±0.0000)\n",
      "Naive_WAVES_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.8180 (±0.0000)\n",
      "Naive_WAVES_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_WAVES_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_WAVES_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2909 (±0.0045)\n",
      "Globally Fitted DynamicVWAP Transformer_WAVES_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6750 (±0.0185)\n",
      "Globally Fitted DynamicVWAP Transformer_WAVES_absolute_vwap_loss: Mean R2 on volume curve: -0.4387 (±0.0485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_TRB_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_TRB_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.5265 (±0.0000)\n",
      "Naive_TRB_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 1.5267 (±0.0000)\n",
      "Naive_TRB_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_TRB_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_TRB_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4249 (±0.0097)\n",
      "Globally Fitted DynamicVWAP Transformer_TRB_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 1.2470 (±0.1016)\n",
      "Globally Fitted DynamicVWAP Transformer_TRB_absolute_vwap_loss: Mean R2 on volume curve: -0.5658 (±0.0569)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_SUSHI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_SUSHI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3505 (±0.0000)\n",
      "Naive_SUSHI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6504 (±0.0000)\n",
      "Naive_SUSHI_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_SUSHI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_SUSHI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2914 (±0.0042)\n",
      "Globally Fitted DynamicVWAP Transformer_SUSHI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5096 (±0.0177)\n",
      "Globally Fitted DynamicVWAP Transformer_SUSHI_absolute_vwap_loss: Mean R2 on volume curve: -0.5499 (±0.0361)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_RUNE_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_RUNE_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3136 (±0.0000)\n",
      "Naive_RUNE_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3391 (±0.0000)\n",
      "Naive_RUNE_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_RUNE_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_RUNE_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2306 (±0.0063)\n",
      "Globally Fitted DynamicVWAP Transformer_RUNE_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1853 (±0.0106)\n",
      "Globally Fitted DynamicVWAP Transformer_RUNE_absolute_vwap_loss: Mean R2 on volume curve: -0.6734 (±0.0432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_SOL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_SOL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2703 (±0.0000)\n",
      "Naive_SOL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2483 (±0.0000)\n",
      "Naive_SOL_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_SOL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_SOL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1867 (±0.0081)\n",
      "Globally Fitted DynamicVWAP Transformer_SOL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1159 (±0.0175)\n",
      "Globally Fitted DynamicVWAP Transformer_SOL_absolute_vwap_loss: Mean R2 on volume curve: -0.7999 (±0.0474)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_EGLD_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_EGLD_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3222 (±0.0000)\n",
      "Naive_EGLD_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6650 (±0.0000)\n",
      "Naive_EGLD_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_EGLD_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_EGLD_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2593 (±0.0043)\n",
      "Globally Fitted DynamicVWAP Transformer_EGLD_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4341 (±0.0219)\n",
      "Globally Fitted DynamicVWAP Transformer_EGLD_absolute_vwap_loss: Mean R2 on volume curve: -0.4618 (±0.0478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ICX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ICX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3187 (±0.0000)\n",
      "Naive_ICX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4872 (±0.0000)\n",
      "Naive_ICX_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ICX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ICX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2598 (±0.0042)\n",
      "Globally Fitted DynamicVWAP Transformer_ICX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3347 (±0.0305)\n",
      "Globally Fitted DynamicVWAP Transformer_ICX_absolute_vwap_loss: Mean R2 on volume curve: -0.4070 (±0.0460)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_STORJ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_STORJ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3947 (±0.0000)\n",
      "Naive_STORJ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7825 (±0.0000)\n",
      "Naive_STORJ_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_STORJ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_STORJ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3057 (±0.0040)\n",
      "Globally Fitted DynamicVWAP Transformer_STORJ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3983 (±0.0222)\n",
      "Globally Fitted DynamicVWAP Transformer_STORJ_absolute_vwap_loss: Mean R2 on volume curve: -0.5057 (±0.0613)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_BLZ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BLZ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4273 (±0.0000)\n",
      "Naive_BLZ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.9526 (±0.0000)\n",
      "Naive_BLZ_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_BLZ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BLZ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3559 (±0.0060)\n",
      "Globally Fitted DynamicVWAP Transformer_BLZ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5778 (±0.0187)\n",
      "Globally Fitted DynamicVWAP Transformer_BLZ_absolute_vwap_loss: Mean R2 on volume curve: -0.3620 (±0.0505)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_UNI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_UNI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3312 (±0.0000)\n",
      "Naive_UNI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.9409 (±0.0000)\n",
      "Naive_UNI_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_UNI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_UNI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2612 (±0.0074)\n",
      "Globally Fitted DynamicVWAP Transformer_UNI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7738 (±0.0767)\n",
      "Globally Fitted DynamicVWAP Transformer_UNI_absolute_vwap_loss: Mean R2 on volume curve: -0.6078 (±0.0298)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_AVAX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_AVAX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2836 (±0.0000)\n",
      "Naive_AVAX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3261 (±0.0000)\n",
      "Naive_AVAX_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_AVAX_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_AVAX_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1995 (±0.0050)\n",
      "Globally Fitted DynamicVWAP Transformer_AVAX_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1670 (±0.0160)\n",
      "Globally Fitted DynamicVWAP Transformer_AVAX_absolute_vwap_loss: Mean R2 on volume curve: -0.7576 (±0.0311)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_FTM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_FTM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3083 (±0.0000)\n",
      "Naive_FTM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3681 (±0.0000)\n",
      "Naive_FTM_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_FTM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_FTM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2259 (±0.0063)\n",
      "Globally Fitted DynamicVWAP Transformer_FTM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1928 (±0.0154)\n",
      "Globally Fitted DynamicVWAP Transformer_FTM_absolute_vwap_loss: Mean R2 on volume curve: -0.7551 (±0.0273)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_FLM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_FLM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3199 (±0.0000)\n",
      "Naive_FLM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4525 (±0.0000)\n",
      "Naive_FLM_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_FLM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_FLM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2532 (±0.0039)\n",
      "Globally Fitted DynamicVWAP Transformer_FLM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2714 (±0.0278)\n",
      "Globally Fitted DynamicVWAP Transformer_FLM_absolute_vwap_loss: Mean R2 on volume curve: -0.5883 (±0.0527)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_ENJ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ENJ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3069 (±0.0000)\n",
      "Naive_ENJ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4553 (±0.0000)\n",
      "Naive_ENJ_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_ENJ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ENJ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2455 (±0.0059)\n",
      "Globally Fitted DynamicVWAP Transformer_ENJ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3209 (±0.0406)\n",
      "Globally Fitted DynamicVWAP Transformer_ENJ_absolute_vwap_loss: Mean R2 on volume curve: -0.5813 (±0.0517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_REN_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_REN_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3873 (±0.0000)\n",
      "Naive_REN_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 1.0116 (±0.0000)\n",
      "Naive_REN_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_REN_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_REN_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3279 (±0.0001)\n",
      "Globally Fitted DynamicVWAP Transformer_REN_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6500 (±0.0228)\n",
      "Globally Fitted DynamicVWAP Transformer_REN_absolute_vwap_loss: Mean R2 on volume curve: -0.5102 (±0.0386)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_KSM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_KSM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3534 (±0.0000)\n",
      "Naive_KSM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6563 (±0.0000)\n",
      "Naive_KSM_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_KSM_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_KSM_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2692 (±0.0029)\n",
      "Globally Fitted DynamicVWAP Transformer_KSM_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4107 (±0.0339)\n",
      "Globally Fitted DynamicVWAP Transformer_KSM_absolute_vwap_loss: Mean R2 on volume curve: -0.5548 (±0.0431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_NEAR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_NEAR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3195 (±0.0000)\n",
      "Naive_NEAR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3721 (±0.0000)\n",
      "Naive_NEAR_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_NEAR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_NEAR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2400 (±0.0066)\n",
      "Globally Fitted DynamicVWAP Transformer_NEAR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1873 (±0.0249)\n",
      "Globally Fitted DynamicVWAP Transformer_NEAR_absolute_vwap_loss: Mean R2 on volume curve: -0.7434 (±0.0290)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_FIL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_FIL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2851 (±0.0000)\n",
      "Naive_FIL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3249 (±0.0000)\n",
      "Naive_FIL_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_FIL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_FIL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2129 (±0.0004)\n",
      "Globally Fitted DynamicVWAP Transformer_FIL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1903 (±0.0089)\n",
      "Globally Fitted DynamicVWAP Transformer_FIL_absolute_vwap_loss: Mean R2 on volume curve: -0.7154 (±0.0286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_AAVE_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_AAVE_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3180 (±0.0000)\n",
      "Naive_AAVE_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3992 (±0.0000)\n",
      "Naive_AAVE_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_AAVE_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_AAVE_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2385 (±0.0045)\n",
      "Globally Fitted DynamicVWAP Transformer_AAVE_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2336 (±0.0398)\n",
      "Globally Fitted DynamicVWAP Transformer_AAVE_absolute_vwap_loss: Mean R2 on volume curve: -0.4646 (±0.0438)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_LRC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_LRC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3372 (±0.0000)\n",
      "Naive_LRC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6072 (±0.0000)\n",
      "Naive_LRC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_LRC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_LRC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2643 (±0.0093)\n",
      "Globally Fitted DynamicVWAP Transformer_LRC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3539 (±0.0535)\n",
      "Globally Fitted DynamicVWAP Transformer_LRC_absolute_vwap_loss: Mean R2 on volume curve: -0.5927 (±0.0344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_RSR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_RSR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4261 (±0.0000)\n",
      "Naive_RSR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.8576 (±0.0000)\n",
      "Naive_RSR_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_RSR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_RSR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3257 (±0.0044)\n",
      "Globally Fitted DynamicVWAP Transformer_RSR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4768 (±0.0259)\n",
      "Globally Fitted DynamicVWAP Transformer_RSR_absolute_vwap_loss: Mean R2 on volume curve: -0.6419 (±0.0769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_MATIC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_MATIC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2391 (±0.0000)\n",
      "Naive_MATIC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2376 (±0.0000)\n",
      "Naive_MATIC_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_MATIC_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_MATIC_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.1817 (±0.0048)\n",
      "Globally Fitted DynamicVWAP Transformer_MATIC_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.1361 (±0.0153)\n",
      "Globally Fitted DynamicVWAP Transformer_MATIC_absolute_vwap_loss: Mean R2 on volume curve: -0.6503 (±0.0408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_OCEAN_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_OCEAN_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3682 (±0.0000)\n",
      "Naive_OCEAN_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7861 (±0.0000)\n",
      "Naive_OCEAN_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_OCEAN_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_OCEAN_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2799 (±0.0026)\n",
      "Globally Fitted DynamicVWAP Transformer_OCEAN_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5118 (±0.0305)\n",
      "Globally Fitted DynamicVWAP Transformer_OCEAN_absolute_vwap_loss: Mean R2 on volume curve: -0.6124 (±0.0473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_BEL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_BEL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3852 (±0.0000)\n",
      "Naive_BEL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7530 (±0.0000)\n",
      "Naive_BEL_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_BEL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_BEL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3125 (±0.0079)\n",
      "Globally Fitted DynamicVWAP Transformer_BEL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4721 (±0.0422)\n",
      "Globally Fitted DynamicVWAP Transformer_BEL_absolute_vwap_loss: Mean R2 on volume curve: -0.4985 (±0.0478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_AXS_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_AXS_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3090 (±0.0000)\n",
      "Naive_AXS_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4147 (±0.0000)\n",
      "Naive_AXS_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_AXS_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_AXS_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2310 (±0.0040)\n",
      "Globally Fitted DynamicVWAP Transformer_AXS_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2153 (±0.0180)\n",
      "Globally Fitted DynamicVWAP Transformer_AXS_absolute_vwap_loss: Mean R2 on volume curve: -0.5295 (±0.0538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_ALPHA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ALPHA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4019 (±0.0000)\n",
      "Naive_ALPHA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 1.2768 (±0.0000)\n",
      "Naive_ALPHA_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_ALPHA_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ALPHA_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3187 (±0.0043)\n",
      "Globally Fitted DynamicVWAP Transformer_ALPHA_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.8098 (±0.0380)\n",
      "Globally Fitted DynamicVWAP Transformer_ALPHA_absolute_vwap_loss: Mean R2 on volume curve: -0.4854 (±0.0541)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ZEN_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ZEN_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3408 (±0.0000)\n",
      "Naive_ZEN_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6850 (±0.0000)\n",
      "Naive_ZEN_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ZEN_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ZEN_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2726 (±0.0080)\n",
      "Globally Fitted DynamicVWAP Transformer_ZEN_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4338 (±0.0490)\n",
      "Globally Fitted DynamicVWAP Transformer_ZEN_absolute_vwap_loss: Mean R2 on volume curve: -0.5801 (±0.0496)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_SKL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_SKL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4284 (±0.0000)\n",
      "Naive_SKL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.8003 (±0.0000)\n",
      "Naive_SKL_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_SKL_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_SKL_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3453 (±0.0109)\n",
      "Globally Fitted DynamicVWAP Transformer_SKL_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4685 (±0.0332)\n",
      "Globally Fitted DynamicVWAP Transformer_SKL_absolute_vwap_loss: Mean R2 on volume curve: -0.7268 (±0.0570)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_GRT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_GRT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3277 (±0.0000)\n",
      "Naive_GRT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4615 (±0.0000)\n",
      "Naive_GRT_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_GRT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_GRT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2521 (±0.0039)\n",
      "Globally Fitted DynamicVWAP Transformer_GRT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2811 (±0.0258)\n",
      "Globally Fitted DynamicVWAP Transformer_GRT_absolute_vwap_loss: Mean R2 on volume curve: -0.6896 (±0.0515)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_1INCH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_1INCH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3451 (±0.0000)\n",
      "Naive_1INCH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6137 (±0.0000)\n",
      "Naive_1INCH_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_1INCH_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_1INCH_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2767 (±0.0053)\n",
      "Globally Fitted DynamicVWAP Transformer_1INCH_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4111 (±0.0296)\n",
      "Globally Fitted DynamicVWAP Transformer_1INCH_absolute_vwap_loss: Mean R2 on volume curve: -0.4827 (±0.0435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_CHZ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_CHZ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3023 (±0.0000)\n",
      "Naive_CHZ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4598 (±0.0000)\n",
      "Naive_CHZ_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_CHZ_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_CHZ_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2345 (±0.0039)\n",
      "Globally Fitted DynamicVWAP Transformer_CHZ_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2794 (±0.0353)\n",
      "Globally Fitted DynamicVWAP Transformer_CHZ_absolute_vwap_loss: Mean R2 on volume curve: -0.6461 (±0.0403)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_SAND_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_SAND_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2703 (±0.0000)\n",
      "Naive_SAND_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3144 (±0.0000)\n",
      "Naive_SAND_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_SAND_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_SAND_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2149 (±0.0057)\n",
      "Globally Fitted DynamicVWAP Transformer_SAND_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2129 (±0.0314)\n",
      "Globally Fitted DynamicVWAP Transformer_SAND_absolute_vwap_loss: Mean R2 on volume curve: -0.5834 (±0.0442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_ANKR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_ANKR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3701 (±0.0000)\n",
      "Naive_ANKR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6916 (±0.0000)\n",
      "Naive_ANKR_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_ANKR_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_ANKR_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2901 (±0.0034)\n",
      "Globally Fitted DynamicVWAP Transformer_ANKR_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4718 (±0.0334)\n",
      "Globally Fitted DynamicVWAP Transformer_ANKR_absolute_vwap_loss: Mean R2 on volume curve: -0.5432 (±0.0561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_LIT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_LIT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3855 (±0.0000)\n",
      "Naive_LIT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6943 (±0.0000)\n",
      "Naive_LIT_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_LIT_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_LIT_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3110 (±0.0093)\n",
      "Globally Fitted DynamicVWAP Transformer_LIT_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.4634 (±0.0703)\n",
      "Globally Fitted DynamicVWAP Transformer_LIT_absolute_vwap_loss: Mean R2 on volume curve: -0.5339 (±0.0695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_CTK_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_CTK_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2783 (±0.0000)\n",
      "Naive_CTK_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.3761 (±0.0000)\n",
      "Naive_CTK_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_CTK_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_CTK_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.2301 (±0.0039)\n",
      "Globally Fitted DynamicVWAP Transformer_CTK_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.2302 (±0.0160)\n",
      "Globally Fitted DynamicVWAP Transformer_CTK_absolute_vwap_loss: Mean R2 on volume curve: -0.4195 (±0.0458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Naive_UNFI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_UNFI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.4168 (±0.0000)\n",
      "Naive_UNFI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.9673 (±0.0000)\n",
      "Naive_UNFI_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  True\n",
      "Globally Fitted DynamicVWAP Transformer_UNFI_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_UNFI_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3372 (±0.0125)\n",
      "Globally Fitted DynamicVWAP Transformer_UNFI_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.6649 (±0.0797)\n",
      "Globally Fitted DynamicVWAP Transformer_UNFI_absolute_vwap_loss: Mean R2 on volume curve: -0.5190 (±0.0492)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Naive_REEF_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Naive_REEF_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3821 (±0.0000)\n",
      "Naive_REEF_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.7124 (±0.0000)\n",
      "Naive_REEF_absolute_vwap_loss: Mean R2 on volume curve: 0.0000 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31975/3040326385.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  vwaps = pd.DataFrame(notionals.values / volumes.values, index=volumes.index, columns = volumes.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Train asset:  False\n",
      "Globally Fitted DynamicVWAP Transformer_REEF_absolute_vwap_loss: Mean Training time: 0.0000 (±0.0000)\n",
      "Globally Fitted DynamicVWAP Transformer_REEF_absolute_vwap_loss: Mean absolute VWAP loss (1e-2): 0.3151 (±0.0092)\n",
      "Globally Fitted DynamicVWAP Transformer_REEF_absolute_vwap_loss: Mean quadratic VWAP loss (1e-4): 0.5899 (±0.0976)\n",
      "Globally Fitted DynamicVWAP Transformer_REEF_absolute_vwap_loss: Mean R2 on volume curve: -0.5974 (±0.0547)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model type</th>\n",
       "      <th>asset</th>\n",
       "      <th>Training Asset</th>\n",
       "      <th>optimization_function</th>\n",
       "      <th>mean_absolute_vwap_loss</th>\n",
       "      <th>std_absolute_vwap_loss</th>\n",
       "      <th>mean_quadratic_vwap_loss</th>\n",
       "      <th>std_quadratic_vwap_loss</th>\n",
       "      <th>mean_r2_volume_curve</th>\n",
       "      <th>std_r2_volume_curve</th>\n",
       "      <th>mean_training_time</th>\n",
       "      <th>std_training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive</td>\n",
       "      <td>BTC</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.160043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Globally Fitted DynamicVWAP Transformer</td>\n",
       "      <td>BTC</td>\n",
       "      <td>True</td>\n",
       "      <td>absolute_vwap_loss</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.036975</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>-0.381714</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>ETH</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.179140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Globally Fitted DynamicVWAP Transformer</td>\n",
       "      <td>ETH</td>\n",
       "      <td>False</td>\n",
       "      <td>absolute_vwap_loss</td>\n",
       "      <td>0.114160</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.050591</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>-0.448697</td>\n",
       "      <td>0.051863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive</td>\n",
       "      <td>BCH</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.295928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Globally Fitted DynamicVWAP Transformer</td>\n",
       "      <td>CTK</td>\n",
       "      <td>False</td>\n",
       "      <td>absolute_vwap_loss</td>\n",
       "      <td>0.230143</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.230183</td>\n",
       "      <td>0.016048</td>\n",
       "      <td>-0.419531</td>\n",
       "      <td>0.045785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Naive</td>\n",
       "      <td>UNFI</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.416821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Globally Fitted DynamicVWAP Transformer</td>\n",
       "      <td>UNFI</td>\n",
       "      <td>True</td>\n",
       "      <td>absolute_vwap_loss</td>\n",
       "      <td>0.337220</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.664860</td>\n",
       "      <td>0.079660</td>\n",
       "      <td>-0.518985</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Naive</td>\n",
       "      <td>REEF</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.382102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Globally Fitted DynamicVWAP Transformer</td>\n",
       "      <td>REEF</td>\n",
       "      <td>False</td>\n",
       "      <td>absolute_vwap_loss</td>\n",
       "      <td>0.315097</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.589914</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>-0.597370</td>\n",
       "      <td>0.054654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model type asset  Training Asset  \\\n",
       "0                                      Naive   BTC            True   \n",
       "1    Globally Fitted DynamicVWAP Transformer   BTC            True   \n",
       "2                                      Naive   ETH           False   \n",
       "3    Globally Fitted DynamicVWAP Transformer   ETH           False   \n",
       "4                                      Naive   BCH            True   \n",
       "..                                       ...   ...             ...   \n",
       "155  Globally Fitted DynamicVWAP Transformer   CTK           False   \n",
       "156                                    Naive  UNFI            True   \n",
       "157  Globally Fitted DynamicVWAP Transformer  UNFI            True   \n",
       "158                                    Naive  REEF           False   \n",
       "159  Globally Fitted DynamicVWAP Transformer  REEF           False   \n",
       "\n",
       "    optimization_function  mean_absolute_vwap_loss  std_absolute_vwap_loss  \\\n",
       "0                     N/A                 0.160043                0.000000   \n",
       "1      absolute_vwap_loss                 0.103224                0.000316   \n",
       "2                     N/A                 0.179140                0.000000   \n",
       "3      absolute_vwap_loss                 0.114160                0.002110   \n",
       "4                     N/A                 0.295928                0.000000   \n",
       "..                    ...                      ...                     ...   \n",
       "155    absolute_vwap_loss                 0.230143                0.003880   \n",
       "156                   N/A                 0.416821                0.000000   \n",
       "157    absolute_vwap_loss                 0.337220                0.012530   \n",
       "158                   N/A                 0.382102                0.000000   \n",
       "159    absolute_vwap_loss                 0.315097                0.009208   \n",
       "\n",
       "     mean_quadratic_vwap_loss  std_quadratic_vwap_loss  mean_r2_volume_curve  \\\n",
       "0                    0.088911                 0.000000              0.000000   \n",
       "1                    0.036975                 0.001401             -0.381714   \n",
       "2                    0.117632                 0.000000              0.000000   \n",
       "3                    0.050591                 0.003312             -0.448697   \n",
       "4                    0.382944                 0.000000              0.000000   \n",
       "..                        ...                      ...                   ...   \n",
       "155                  0.230183                 0.016048             -0.419531   \n",
       "156                  0.967334                 0.000000              0.000000   \n",
       "157                  0.664860                 0.079660             -0.518985   \n",
       "158                  0.712378                 0.000000              0.000000   \n",
       "159                  0.589914                 0.097566             -0.597370   \n",
       "\n",
       "     std_r2_volume_curve  mean_training_time  std_training_time  \n",
       "0               0.000000                 0.0                0.0  \n",
       "1               0.071847                 0.0                0.0  \n",
       "2               0.000000                 0.0                0.0  \n",
       "3               0.051863                 0.0                0.0  \n",
       "4               0.000000                 0.0                0.0  \n",
       "..                   ...                 ...                ...  \n",
       "155             0.045785                 0.0                0.0  \n",
       "156             0.000000                 0.0                0.0  \n",
       "157             0.049187                 0.0                0.0  \n",
       "158             0.000000                 0.0                0.0  \n",
       "159             0.054654                 0.0                0.0  \n",
       "\n",
       "[160 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = create_full_comparison(assets = all_assets, train_assets = train_assets, lookback = lookback, n_ahead = n_ahead, sig_lookback = sig_lookback, verbose=True)\n",
    "display(results_df)\n",
    "results_df.to_csv(f'full_results_200_transformer_{lookback}_{n_ahead}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
